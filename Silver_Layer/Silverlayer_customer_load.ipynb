{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b342e49-eaa9-419e-8bcb-180a8e5ad3e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"use globalretail_silver\")\n",
    "spark.sql(\"\"\"\n",
    "create table if not exists silver_customers (\n",
    "    customer_id string,\n",
    "    name string,\n",
    "    email string,\n",
    "    country string,\n",
    "    customer_type string,\n",
    "    registration_date date,\n",
    "    age int,\n",
    "    gender string,\n",
    "    total_purchases int,\n",
    "    customer_segment string,\n",
    "    days_since_registration int,\n",
    "    last_updated timestamp\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40d08855-0a0c-43aa-b15f-a13aae83a3ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"use globalretail_silver\")\n",
    "last_processed_df = spark.sql(\"select max(last_updated) as last_processed from silver_customers\")\n",
    "\n",
    "last_processed_timestamp = last_processed_df.collect()[0]['last_processed']\n",
    "\n",
    "if last_processed_timestamp is None:\n",
    "  last_processed_timestamp = '1900-01-01 00:00:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c06aac-12f0-448f-847d-ce09f1889d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "create or replace temporary view bronze_incremental as\n",
    "select * from globalretail_bronze.bronze_customer c\n",
    "where c.ingestion_timestamp > '{last_processed_timestamp}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aefd47d-29d6-4d42-9d0c-53793cb1df51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from bronze_incremental\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c10d3abc-0140-4323-b14d-49560938a46b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df_email_validation = df.withColumn(\n",
    "    \"email_valid\",\n",
    "    when(col(\"email\").isNull(), \"NULL\").otherwise(\"NOT NULL\")\n",
    ")\n",
    "display(df_email_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45fada38-e513-4720-81eb-bd991aa2124a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_age_validation = df_email_validation.withColumn(\n",
    "    \"age_valid\",\n",
    "    when((col(\"age\") >= 18) & (col(\"age\") <= 100), \"VALID\").otherwise(\"INVALID\")\n",
    ")\n",
    "display(df_age_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1506e36e-5c32-42e3-95bd-00ff3152b725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_segmented = df_age_validation.withColumn(\n",
    "    \"customer_segment\",\n",
    "    when(col(\"total_purchases\") > 10000, \"High Value\")\n",
    "    .when(col(\"total_purchases\") > 5000, \"Medium Value\")\n",
    "    .otherwise(\"Low Value\")\n",
    ")\n",
    "display(df_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf821f09-07ff-4159-bd09-2ed4e93e6f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import datediff, current_date\n",
    "\n",
    "df_with_days_since_registration = df_segmented.withColumn(\n",
    "    \"days_since_registration\",\n",
    "    datediff(current_date(), col(\"registration_date\"))\n",
    ")\n",
    "display(df_with_days_since_registration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a95cbf7-602a-4cae-ba91-7ac358c0914f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_cleaned = df_with_days_since_registration.filter(col(\"total_purchases\") >= 0)\n",
    "display(df_cleaned)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silverlayer_customer_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
